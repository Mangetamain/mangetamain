# Formulations math√©matiques ‚Äî indicateurs pour visualisation

---

## üìä Ressources Compl√©mentaires

üó∫Ô∏è **[Sch√©ma d'Architecture Interactive](https://htmlpreview.github.io/?https://github.com/Mangetamain/mangetamain/blob/main/docs/recipe_script_diagram.html)** - Visualisation compl√®te du syst√®me de pr√©traitement des recettes

---

## 1. Jaccard (similarit√© d'ensembles)

<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}J(A,B)=\frac{|A\cap%20B|}{|A\cup%20B|}" alt="Jaccard Formula"/>
</p>

**D√©finition :** Soient A et B des ensembles d'ingr√©dients, cette formule mesure la proportion d'ingr√©dients communs sur le total d'ingr√©dients uniques.

**Cas particulier :** Si |A ‚à™ B| = 0 alors J(A,B) = 0

---

## 2. TF‚ÄìIDF et similarit√© cosinus

**TF-IDF :**
<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}w_{t,d}=\mathrm{tf}_{t,d}\times\mathrm{idf}_t" alt="TF-IDF Formula"/>
</p>

**D√©finition :** Pour un terme t, document d (recette) et corpus de N documents, le poids TF-IDF combine la fr√©quence locale (tf) et l'importance globale (idf).

**Similarit√© cosinus :**
<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}\cos(v_d,q)=\frac{v_d\cdot%20q}{\|v_d\|_2\;\|q\|_2}" alt="Cosine Similarity"/>
</p>

**D√©finition :** Mesure l'angle entre les vecteurs TF-IDF de la requ√™te utilisateur et d'une recette. Valeurs dans [0,1] pour vecteurs non-n√©gatifs.

---

## 3. Moyenne des notes et normalisation Min‚ÄìMax

**Moyenne des notes :**
<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}\bar{r}=\frac{1}{m}\sum_{i=1}^m%20r_i" alt="Average Rating"/>
</p>

**D√©finition :** Calcule la note moyenne d'une recette sur m √©valuations.

**Normalisation Min-Max :**
<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}\tilde{r}=\begin{cases}\frac{\bar{r}-\min(\bar{r})}{\max(\bar{r})-\min(\bar{r})}&\text{si%20}\max\neq\min\\0.5&\text{si%20}\max=\min\end{cases}" alt="Min-Max Normalization"/>
</p>

**D√©finition :** Transforme les notes dans l'intervalle [0,1] pour permettre la combinaison avec d'autres indicateurs.

---

## 4. Popularit√© (normalisation du nombre d'interactions)

<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}\text{pop}_r=\frac{n_r-\min(n)}{\max(n)-\min(n)}" alt="Popularity Normalization"/>
</p>

**D√©finition :** Normalise le nombre d'avis/interactions n_r d'une recette dans [0,1]. Mesure la confiance bas√©e sur le volume d'interactions.

---

## 5. Mise √† l'√©chelle robuste (optionnelle)

<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}n'_r=\log(1+n_r)" alt="Log Scaling"/>
</p>

**D√©finition :** Pour r√©duire l'effet des outliers, appliquer une transformation logarithmique avant la normalisation Min-Max.

---

## 6. Score hybride final

<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}\text{score}_r=\alpha\cdot%20J(A,B_r)+\delta\cdot\cos(v_{B_r},q)+\beta\cdot\tilde{r}+\gamma\cdot\text{pop}_r" alt="Hybrid Score"/>
</p>

**D√©finition :** Combine les quatre indicateurs avec des poids configurables pour obtenir un score final de recommandation.

**Valeurs par d√©faut :** Œ±=0.4 (Jaccard), Œ≤=0.3 (Rating), Œ≥=0.2 (Popularit√©), Œ¥=0.1 (Cosinus)

---

## 7. Traitement des cas limites

**Gestion des erreurs courantes :**
- **Divisions par z√©ro :** Retourner 0 ou valeur neutre (ex. 0.5 pour ratings uniformes)
- **Donn√©es manquantes :** Remplacer par valeur neutre avant combinaison
- **Listes vides :** Jaccard = 0, Cosinus utilise fallback vers Jaccard
- **√âchec TF-IDF :** Fallback automatique vers similarit√© de Jaccard

---

## 8. M√©triques d'√©valuation

**Precision@k :**
<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}\mathrm{P@k}=\frac{1}{k}\sum_{i=1}^k\mathbf{1}[\text{rel}_i=1]" alt="Precision at k"/>
</p>

**D√©finition :** Proportion d'√©l√©ments pertinents parmi les k premiers r√©sultats recommand√©s.

**NDCG@k :**
<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}\mathrm{NDCG@k}=\frac{\mathrm{DCG@k}}{\mathrm{IDCG@k}}" alt="NDCG at k"/>
</p>

**D√©finition :** Normalized Discounted Cumulative Gain, prend en compte la position des √©l√©ments pertinents (plus haut = mieux).

**MRR :**
<p align="center">
<img src="https://latex.codecogs.com/svg.latex?\color{white}\mathrm{MRR}=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\frac{1}{\text{rank}_q}" alt="Mean Reciprocal Rank"/>
</p>

**D√©finition :** Mean Reciprocal Rank, mesure la position moyenne du premier √©l√©ment pertinent trouv√©.

---

## 9. Recommandations d'usage

**Ajustement des poids selon le contexte :**

| Contexte | Poids √† augmenter | Objectif |
|----------|-------------------|----------|
| **üîç D√©couverte** | Œ≥ (Popularit√©) | Recommander des recettes √©prouv√©es |
| **üéØ Personnalisation** | Œ± (Jaccard) | Correspondance exacte d'ingr√©dients |
| **‚≠ê Qualit√©** | Œ≤ (Rating) | Privil√©gier les meilleures notes |
| **üß† S√©mantique** | Œ¥ (Cosinus) | Similarit√© lexicale avanc√©e |

**Impl√©mentation pratique :**
- Toujours normaliser les composantes en [0,1] avant combinaison
- Pr√©voir des fallbacks pour l'indisponibilit√© de sklearn
- Instrumenter avec des m√©triques Precision@k et Coverage
- Tester diff√©rents poids via A/B testing

---