# Tests - MangeTaMain

Ce document explique comment lancer et utiliser les tests unitaires pour l'application MangeTaMain.

## ğŸ§ª Configuration des Tests

Le projet utilise une infrastructure de tests complÃ¨te avec :
- **pytest** pour les tests unitaires
- **coverage.py** pour la couverture de code
- **Docker** pour l'environnement de test isolÃ©
- **Mocking** pour les dÃ©pendances externes

## ğŸš€ Lancement des Tests

### Option 1: Script de test automatisÃ© (RecommandÃ©)

Le script `run-tests.sh` fournit une interface simple pour exÃ©cuter les tests :

```bash
# Lancer tous les tests unitaires
./run-tests.sh -u

# Lancer tous les tests (unitaires + intÃ©gration)
./run-tests.sh

# Mode dÃ©veloppement interactif
./run-tests.sh -d

# GÃ©nÃ©rer seulement le rapport de couverture
./run-tests.sh -c

# Forcer la reconstruction de l'image Docker
./run-tests.sh -u --build

# Mode verbose
./run-tests.sh -u --verbose

# Nettoyer l'environnement de test
./run-tests.sh --clean
```

### Option 2: Docker Compose direct

```bash
# DÃ©marrer les services de test
docker-compose --profile testing up -d preprocessing

# ExÃ©cuter les tests unitaires
docker-compose --profile testing run --rm tests poetry run pytest tests/unit/

# ExÃ©cuter avec couverture
docker-compose --profile testing run --rm tests poetry run pytest tests/unit/ --cov=src --cov-report=html

# Mode dÃ©veloppement interactif
docker-compose --profile testing run --rm tests-dev
```

### Option 3: DÃ©veloppement local (si Poetry installÃ©)

```bash
# Installer les dÃ©pendances de dÃ©veloppement
poetry install --with dev

# Lancer les tests unitaires
poetry run pytest tests/unit/

# Avec couverture
poetry run pytest tests/unit/ --cov=src --cov-report=html --cov-report=term-missing
```

## ğŸ† SuccÃ¨s de Couverture

### AmÃ©lioration Spectaculaire
- **Avant** : 53% de couverture globale
- **AprÃ¨s** : 86% de couverture globale (+33 points !)
- **RÃ©sultat** : Objectif 80% largement dÃ©passÃ©

### DÃ©tail par Module
| Module | Couverture Avant | Couverture AprÃ¨s | AmÃ©lioration |
|--------|------------------|------------------|--------------|
| `core/app.py` | 63% | 99% | +36 points âœ¨ |
| `main.py` | 0% | 100% | +100 points ğŸš€ |
| `config.py` | 0% | 100% | +100 points ğŸš€ |
| `styles.py` | 80% | 100% | +20 points â­ |
| `recommendation_engine.py` | 74% | 91% | +17 points ğŸ“ˆ |
| `components.py` | ~70% | 91% | +21 points ğŸ“Š |
| `data_manager.py` | ~85% | 100% | +15 points ğŸ’¯ |

## ğŸ“Š Rapports de Test

### Couverture de Code

Les rapports de couverture sont gÃ©nÃ©rÃ©s automatiquement :
- **Rapport HTML** : Accessible dans le volume Docker `test_reports/htmlcov/index.html`
- **Rapport XML** : Pour intÃ©gration CI/CD dans `test_reports/coverage.xml`
- **Rapport Terminal** : AffichÃ© directement dans la console

```bash
# Voir les rapports gÃ©nÃ©rÃ©s
docker-compose --profile testing exec tests ls -la /app/test-reports/
```

### MÃ©triques Actuelles

- âœ… **121/122 tests** passent avec succÃ¨s (99.2% de rÃ©ussite)
- ğŸ“ˆ **86% de couverture** de code globale (objectif dÃ©passÃ© !)
- ğŸ¯ Tests couvrent exhaustivement tous les modules :
  - `core/app.py` (99% couvert - quasi-complet)
  - `main.py` (100% couvert - complet)
  - `config.py` (100% couvert - complet)  
  - `styles.py` (100% couvert - complet)
  - `RecommendationEngine` (91% couvert - excellent)
  - `UIComponents` (91% couvert - excellent)
  - `DataManager` (100% couvert - complet)

## ğŸ—ï¸ Structure des Tests

```
tests/
â”œâ”€â”€ unit/                                      # Tests unitaires (suite exhaustive)
â”‚   â”œâ”€â”€ test_config_module.py                 # Tests module configuration
â”‚   â”œâ”€â”€ test_config.py                        # Tests configuration complÃ¨te (100%)
â”‚   â”œâ”€â”€ test_core_app_targeted.py            # Tests ciblÃ©s core/app.py (99%)
â”‚   â”œâ”€â”€ test_core_app.py                     # Tests principaux core/app.py
â”‚   â”œâ”€â”€ test_data_manager.py                 # Tests gestionnaire donnÃ©es (100%)
â”‚   â”œâ”€â”€ test_final_coverage.py              # Tests couverture finale
â”‚   â”œâ”€â”€ test_main_module.py                 # Tests module principal
â”‚   â”œâ”€â”€ test_recommendation_engine_additional.py  # Tests moteur (complÃ©ment)
â”‚   â”œâ”€â”€ test_recommendation_engine_extended.py   # Tests moteur (Ã©tendu)
â”‚   â”œâ”€â”€ test_recommendation_engine.py       # Tests moteur recommandation (91%)
â”‚   â”œâ”€â”€ test_src_main.py                    # Tests src/main.py (100%)
â”‚   â”œâ”€â”€ test_styles.py                      # Tests gestionnaire styles (100%)
â”‚   â”œâ”€â”€ test_ui_components_extended.py      # Tests UI composants (Ã©tendu)
â”‚   â”œâ”€â”€ test_ui_components.py               # Tests composants UI (91%)
â”‚   â”œâ”€â”€ test_ui_final.py                    # Tests UI finaux
â”‚   â””â”€â”€ test_ui_intensive.py                # Tests UI intensifs
â””â”€â”€ integration/                            # Tests d'intÃ©gration
    â”œâ”€â”€ test_app_integration.py             # Tests intÃ©gration app
    â””â”€â”€ test_full_workflow.py               # Tests workflow complet
```

## ğŸ› ï¸ Tests Disponibles

### Tests Unitaires (Suite Exhaustive)
- **Configuration** : Tests complets des structures de config (100% couverture)
- **Application Principale** : Tests ciblÃ©s pour toutes les branches logiques (99% couverture)
- **RecommendationEngine** : Calcul scores composites, normalisation, gestion erreurs (91% couverture)
- **UIComponents** : Tous composants Streamlit avec mocking avancÃ© (91% couverture)
- **DataManager** : Chargement, validation, gestion cache (100% couverture)
- **StyleManager** : CSS, thÃ¨mes, styles responsifs (100% couverture)
- **Main Module** : Point d'entrÃ©e et orchestration (100% couverture)

### Tests d'IntÃ©gration
- **Workflow complet** : Pipeline de recommandation end-to-end
- **IntÃ©gration app** : Tests des interactions entre composants

### StratÃ©gies de Test
- **Mocking extensif** : Streamlit, pandas, fichiers systÃ¨me
- **Tests de branches** : Couverture de tous les chemins logiques
- **Tests d'erreurs** : Gestion robuste des cas d'Ã©chec
- **Tests de performance** : Validation des temps de rÃ©ponse

## ğŸ”§ DÃ©veloppement des Tests

### Ajouter un nouveau test

1. CrÃ©er le fichier dans `tests/unit/` ou `tests/integration/`
2. Utiliser pytest et les fixtures disponibles
3. Mocker les dÃ©pendances externes (Streamlit, pandas, etc.)

Exemple :
```python
import pytest
from unittest.mock import patch, Mock
from src.engines.recommendation_engine import RecommendationEngine

def test_nouvelle_fonctionnalite():
    with patch('streamlit.cache_data'):
        result = RecommendationEngine.nouvelle_methode()
        assert result is not None
```

### Fixtures Disponibles

- `sample_recipe` : Recette d'exemple
- `sample_recipes_df` : DataFrame de recettes de test
- `sample_interactions_df` : DataFrame d'interactions utilisateur

## ğŸ³ Configuration Docker

Les tests utilisent des services Docker dÃ©diÃ©s :

- **tests** : Service principal pour l'exÃ©cution des tests
- **tests-dev** : Service interactif pour le dÃ©veloppement
- **preprocessing** : Service de prÃ©paration des donnÃ©es

### Variables d'environnement

```yaml
POETRY_CACHE_DIR: /tmp/poetry_cache
PYTHONPATH: /app:/preprocessing
```

## âš¡ Commandes Rapides

```bash
# Test rapide
./run-tests.sh -u

# Tests de performance
./run-tests.sh -p

# DÃ©veloppement avec hot-reload
./run-tests.sh -d

# Nettoyer aprÃ¨s tests
./run-tests.sh --clean

# Voir l'aide
./run-tests.sh --help
```

## ğŸš¨ DÃ©pannage

### ProblÃ¨mes Courants

1. **Tests ne dÃ©marrent pas** :
   ```bash
   # VÃ©rifier Docker
   docker --version
   docker-compose --version
   
   # Nettoyer l'environnement
   ./run-tests.sh --clean
   ```

2. **Erreurs de dÃ©pendances** :
   ```bash
   # Forcer la reconstruction
   ./run-tests.sh -u --build
   ```

3. **ProblÃ¨mes de volumes** :
   ```bash
   # Nettoyer les volumes Docker
   docker volume prune
   ```

### Logs de Debug

```bash
# Voir les logs du service de test
docker-compose --profile testing logs tests

# Mode verbose
./run-tests.sh -u --verbose
```

## ğŸ“‹ Prochaines Ã‰tapes

- [x] ~~AmÃ©liorer la couverture de code (objectif : 80%)~~ **âœ… ACCOMPLI : 86% atteint !**
- [x] ~~Ajouter des tests de performance~~ **âœ… ACCOMPLI : Support via -p flag**
- [x] ~~IntÃ©gration CI/CD avec GitHub Actions~~ **âœ… ACCOMPLI : Workflows configurÃ©s**
- [ ] Tests de rÃ©gression automatisÃ©s
- [ ] Tests end-to-end avec Selenium
- [ ] Benchmarking des performances de recommandation
- [ ] Tests de charge et de stress

---

**ğŸ’¡ Conseil** : Utilisez toujours `./run-tests.sh -u` pour un test rapide avant de commiter vos changements !