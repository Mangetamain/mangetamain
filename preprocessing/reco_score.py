import pandas as pd
import numpy as np
from typing import List, Set

# Import conditionnel de sklearn avec fallback
try:
    from sklearn.preprocessing import MinMaxScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

class RecipScorer:
    """Classe pour scorer et recommander des recettes"""
    
    def __init__(self, alpha=0.5, beta=0.3, gamma=0.2):
        """
        Args:
            alpha: Poids pour la similarit√© des ingr√©dients
            beta: Poids pour le rating moyen
            gamma: Poids pour le nombre de reviews
        """
        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma
        
        # Utiliser sklearn si disponible, sinon normalisation manuelle
        if SKLEARN_AVAILABLE:
            self.scaler = MinMaxScaler()
        else:
            self.scaler = None
    
    @staticmethod
    def jaccard_similarity(list1, list2) -> float:
        """Calcule la similarit√© de Jaccard entre deux listes"""
        if not list1 or not list2:
            return 0.0
        
        set1 = set(list1) if not isinstance(list1, set) else list1
        set2 = set(list2) if not isinstance(list2, set) else list2
        
        intersection = len(set1.intersection(set2))
        union = len(set1.union(set2))
        
        return intersection / union if union > 0 else 0.0
    
    def normalize_series(self, series):
        """Normalisation entre 0 et 1 (avec ou sans sklearn)"""
        if self.scaler is not None and SKLEARN_AVAILABLE:
            # Utiliser sklearn
            return pd.Series(
                self.scaler.fit_transform(series.values.reshape(-1, 1)).flatten(),
                index=series.index
            )
        else:
            # Normalisation manuelle
            min_val = series.min()
            max_val = series.max()
            if max_val == min_val:
                return pd.Series([0.5] * len(series), index=series.index)
            return (series - min_val) / (max_val - min_val)
    
    def compute_base_score(self, recipes_df, interactions_df):

        if len(interactions_df) == 0:
            return pd.DataFrame(columns=['id', 'mean_rating_norm', 'popularity'])
        
        # Grouper les interactions par recipe_id
        stats = interactions_df.groupby("recipe_id").agg(
            mean_rating=('rating', 'mean'),
            n_reviews=('rating', 'count')
        ).reset_index()
        
        #  CORRECTION CRITIQUE: Renommer pour matcher recipes_df
        stats = stats.rename(columns={'recipe_id': 'id'})
        
        # Normalisation
        if len(stats) > 0:
            stats["mean_rating_norm"] = self.normalize_series(stats['mean_rating'])
            stats["popularity"] = self.normalize_series(stats['n_reviews'])
        else:
            stats["mean_rating_norm"] = 0.5
            stats["popularity"] = 0.0
        
        return stats
    
    def recommend(self, recipes_df, interactions_df, user_ingredients, time_limit=None, top_n=10):
        """
         CORRECTION: Recommande des recettes avec gestion d'erreurs robuste
        """
        # Copier pour √©viter les modifications
        df = recipes_df.copy()
        
        # Filtrer par temps si sp√©cifi√©
        if time_limit and 'minutes' in df.columns:
            initial_count = len(df)
            df = df[df['minutes'] <= time_limit]
            print(f"‚è±Ô∏è Filtrage temps: {initial_count} ‚Üí {len(df)} recettes")
        
        # Calculer la similarit√© Jaccard
        ingredient_col = 'normalized_ingredients' if 'normalized_ingredients' in df.columns else 'ingredients'
        print(f" Utilisation de la colonne: {ingredient_col}")
        
        df["jaccard"] = df[ingredient_col].apply(
            lambda ing: self.jaccard_similarity(user_ingredients, ing) if (ing is not None and len(ing) > 0 if isinstance(ing, list) else pd.notnull(ing)) else 0
        )
        
        # Calculer les scores de base
        stats = self.compute_base_score(recipes_df, interactions_df)
        print(f" Stats calcul√©es pour {len(stats)} recettes")
        
        # üî• MERGER CORRIG√â: maintenant les deux ont 'id'
        df = df.merge(stats, on="id", how="left")
        print(f" Apr√®s fusion: {len(df)} recettes")
        
        # Remplir les valeurs manquantes
        df["mean_rating_norm"] = df["mean_rating_norm"].fillna(0.5)
        df["popularity"] = df["popularity"].fillna(0.0)
        
        # Score final
        df["score"] = (
            self.alpha * df['jaccard'] +
            self.beta * df['mean_rating_norm'] +
            self.gamma * df['popularity']
        )
        
        #  COLONNES CORRIG√âES: utiliser 'id' partout
        columns_to_return = [
            'id', 'name', 'jaccard', 'mean_rating_norm', 
            'popularity', 'score'
        ]
        
        # Ajouter la colonne d'ingr√©dients si elle existe
        if ingredient_col in df.columns:
            columns_to_return.append(ingredient_col)
        
        # Ajouter 'minutes' si elle existe
        if 'minutes' in df.columns:
            columns_to_return.append('minutes')
        
        # Filtrer les colonnes existantes
        existing_columns = [col for col in columns_to_return if col in df.columns]
        
        result = df.sort_values("score", ascending=False).head(top_n)
        print(f" Retour de {len(result)} recommandations")
        
        return result[existing_columns]

# Alias pour compatibilit√©
RecipeScorer = RecipScorer

# Test direct du module
if __name__ == "__main__":
    print(" Test direct du module reco_score")
    scorer = RecipScorer()
    
    # Test Jaccard
    user_ing = ["chicken", "onion"]
    recipe_ing = ["chicken", "tomato", "onion"]
    jaccard = RecipScorer.jaccard_similarity(user_ing, recipe_ing)
    print(f"Test Jaccard: {jaccard:.3f}")
    print(" Module reco_score pr√™t!")